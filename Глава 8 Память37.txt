# Глава 8. Архитектура знаний и памяти ИИ (кодовое имя: «Память37»)

Цель главы — превратить знания о мире, правилах и ходе кампании в управляемую, проверяемую и дешёвую в эксплуатации систему памяти, чтобы ведущий-ИИ и NPC отвечали консистентно, не выходили за канон и «помнили» прошлые события.

## 8.0 Принципы (зачем это нужно)

1.  **Разделяй и властвуй.** Делаем **отдельные хранилища** для разных типов знаний (SRD/правила, лор/мир, эпизоды/сводки, «карточки арта»).  
    Зачем: разная «физика» данных → разные политики версий/TTL/фильтров → меньше шума в промпте, предсказуемый ретрив.
2.  **Многоуровневая память.** Разводим **рабочую** (prompt на один запрос), **краткосрочную** (thread-state шага/сессии), **долгосрочную** (персистентные сводки/факты/NPC-отношения).  
    Зачем: окно контекста всегда ограничено; уровни позволяют не терять важное, не раздувая промпт. (См. «checkpointers/threads/stores» в LangGraph — это базовый механизм долговечности и HITL/отката состояния.)
3.  **Гибридный поиск.** Извлекаем контекст **BM25 + dense** (вектор) и объединяем результаты **RRF** (Reciprocal Rank Fusion).  
    Зачем: keyword ловит редкие имена/спелл-кейворды, dense — смысл; RRF стабилизирует итоговый топ.
4.  **Экономный recall, дорогой precision.** Берём **k=8–12** и лёгкий **LLM-rerank** только по top-20 — дешево и снижает мусор.
5.  **Эмбеддинги «матрёшка».** Используем text-embedding-3-large с **уменьшенной размерностью** (обычно 1024–1536) — почти тот же recall за меньшие деньги/память (матрешечное обучение/«Matryoshka»).
6.  **Где интеллект — где детерминизм.** Решения по правилам/эффектам/числам — только движок; ИИ — нарратив и формулировки. Память пишет **только движок**/редактор (LLM не «самозапоминает» без верификации).
7.  **Операбельность.** Любые изменения знаний — сначала **stage-индекс**, затем атомарный **swap alias**. Бэкапы и воспроизводимый re-index из сырья — обязательны.

## 8.1 Таксономия знаний и хранилища

### 8.1.1 Домены знаний

- **SRD/Правила** — норматив, откуда берём «как считать».
- **Lore/Мир** — биографии, локации, фракции, хронология, термины, стилистика.
- **Episode/Сводки** — краткие JSON-события хода (post-turn summaries) + факты/флаги прогресса.
- **NPC-профили** — статические атрибуты + **динамические отношения** (disposition) к партии/героям.
- **ArtCards** — карточки визуала (не пиксели, а текст: промпт, теги, стиль, seed) для визуальной консистентности.

### 8.1.2 Индексы и физика

- **Vector store (pgvector)**: для SRD/Lore/Episode/ArtCards (колонки: embedding, metadata JSON).
- **Keyword (BM25)**: для SRD/Lore.
- **Graph (опционально GraphRAG)**: узлы — персонажи/локации/объекты, рёбра — отношения/квестовые связи; поддерживает «рассуждение по связям», community-summaries.

Зачем: разделение = разные фильтры/версии/TTL, а гибридный запрос даёт стабильный контекст под промпт.

## 8.2 Инжест, нормализация, чанкинг, версионирование

### 8.2.1 Инжест-пайплайн

1.  **Normalize**: конверт в **JSON** с оглавлением/ID/метаданными.
2.  **Chunk**: **семантический** (по заголовкам/правилу/сущности), 500–1500 токенов.
3.  **Embed**: text-embedding-3-large с **dimensions=1024–1536** (для лора); 768–1024 — для эпизодов. (Матрешечная тренировка поддерживает хорошую деградацию по размерности.)
4.  **Index**: upsert в векторное + keyword; опционально — построение KG (GraphRAG) и комьюнити-сводок.

### 8.2.2 Версионирование

- **SemVer** на уровне чанка (version), плюс алиасы индекса latest, stage.
- **Правка лора** — только через review (HITL) и канареечный swap alias; журнал изменений.

Зачем: rollback-дружелюбность, «зелёное» переключение и воспроизводимый re-index.

## 8.3 Эмбеддинги и параметры извлечения

- **Модель**: text-embedding-3-large (OpenAI), **уменьшенные размерности** 1024–1536 для лора/правил, 768–1024 для эпизодов (экономия RAM/стоимости при высокой релевантности за счёт MRL/«Matryoshka»).
- **Гибрид**: BM25 + vector; **RRF** для слияния ранжирований. Типовые k:
    - vector: top-12 (SRD/Lore), top-8 (Episode/Art)
    - keyword: top-50 (BM25), затем **RRF** → итоговые top-8 в контекст. ([Microsoft Learn](https://learn.microsoft.com/en-us/azure/search/hybrid-search-ranking"%20\o%20"Hybrid%20search%20scoring%20%28RRF%29%20-%20Azure%20AI%20Search%20|%20Microsoft%20Learn))
- **Лёгкий rerank**: nano-модель по 12–20 кандидатам → top-8; экономит токены и повышает точность.

Зачем: гибрид уменьшает промахи по «редким именам», RRF аккуратно сливает сигналы без тюнинга; rerank чистит хвост.

## 8.4 Слои памяти и политика обновлений

### 8.4.1 Слои

- **Рабочая память** — конкретный prompt (сцена).
- **Краткосрочная** — состояние треда/шага (LangGraph **thread/checkpoints**), доступно для HITL/«отката».
- **Долгосрочная** — структурные **сводки** сцен, факты/флаги прогресса, отношения NPC, ArtCards; доступ через store/namespace.

### 8.4.2 Кто пишет память

- **Только движок/редактор.** LLM не записывает в долгую память без явного решения движка (вопрос безопасности/качества).
- **Когда писать**: **после каждого хода/сцены** (post-turn), а также по событию (получен артефакт, смена отношения NPC, окончание квеста).

Зачем: управляемость и воспроизводимость — никакой «самозаписи» от модели.

## 8.5 Форматы данных (JSON-схемы)

### 8.5.1 Сводка сцены (Episodic Summary)

{

"summary_id": "sum_2025_08_27_0142",

"campaign_id": "camp_123",

"party_id": "pty_001",

"scene_id": "scn_042",

"when": "2025-08-27T11:42:00Z",

"who": {

"players": \["p_A", "p_B"\],

"npcs": \["npc_LiShen"\]

},

"where": {

"location_id": "loc_moon_bridge",

"tags": \["night","mist"\]

},

"what": {

"event": "bargain",

"outcome": "partial_success",

"rolls": \[{"who":"p_A","d20":14,"dc":12,"effect":"+2 insight"}\],

"loot": \[{"item_id":"amulet_moon","qty":1}\]

},

"flags": {

"quest_moon_key": "obtained",

"gate_moon_door": "open"

},

"relations_delta": \[

{"npc_id":"npc_LiShen","towards":"party","delta":+1,"reason":"kept promise"}

\],

"notes": "short prose, ≤40 tokens",

"version": "1.0.0"

}

**Смысл:** атомарный, машиночитаемый снимок «кто-где-что-чем закончилось» + изменения отношений и флаги гейтов — это переживёт окно контекста и даст LLM ключевые факты без перегруза.

### 8.5.2 Профиль NPC (динамический слой)

{

"npc_id": "npc_LiShen",

"static": {

"name": "Ли-Шэнь",

"archetype": "ronin",

"voice_tts": "asian_male_light_smoke",

"secrets": \["scar_left_cheek_reason"\],

"lore_refs": \["lore_ronin_code"\]

},

"dynamic": {

"disposition": {"party_id:pty_001": 2},

"memory": \[

{"summary_id":"sum_2025_08_27_0142","impact":"trust+1"}

\]

},

"version": "1.1.0"

}

**Смысл:** одно место истины для «как относится к нам NPC и почему». Обновляет **движок** по правилам, LLM только читает.

### 8.5.3 ArtCard (визуальная консистентность)

{

"image_id": "img_8f3c",

"scene_id": "scn_042",

"cdn_url": "https://cdn/.../img_8f3c.webp",

"prompt_text": "moonlit bridge, mist, ronin with scar on left cheek…",

"entities": {"npc":\["npc_LiShen"\], "location":\["loc_moon_bridge"\]},

"visual_tags": \["moonlight","mist","blue-gold","katana","scar_left_cheek"\],

"style": {"preset": "ukiyo-e-modern", "seed": 12345},

"moderation": {"safe": true},

"created_at": "2025-08-27T11:42:05Z",

"embedding": {"model":"text-embedding-3-large","dims": 1024, "vec": "\[…\]"}

}

**Смысл:** мы не «понимаем пиксели», мы фиксируем **словесные факты и стиль** изображения, чтобы следующая сцена и новый арт не «забыли шрам/палитру». Эмбеддинг опционален (дешёвый).

## 8.6 Сборка контекста (Prompt Assembly)

На генерацию **каждой сцены** подаётся:

1.  **System**: тон-гайд, стилевые правила, запреты, роль модели («нарратор», «правила — за движком»).
2.  **Rules (SRD)**: только если нужны термины/референсы (через ретрив 1–2 чанка).
3.  **Lore**: top-N чанков по текущей локации/NPC.
4.  **Episode**: последние **1–2 сводки** + релевантные факты/флаги.
5.  **NPC**: профиль задействованных NPC (статик + последние изменения отношения).
6.  **Art context** (если генерим арт): ArtCard-теги/стиль в коротком блоке.
7.  **User**: ввод игрока / выбор партии.

Зачем: компактный, но насыщенный контекст с «золотыми» фактами; всё остальное — по запросу через MCP-инструменты (rules_lookup, lore_search, session_fetch и т.д.).

## 8.7 Поисковая стратегия и параметры

- **Гибрид**: BM25 + vector; итог — **RRF**. (Azure AI Search задокументировал RRF как стандартный способ фьюжна ранжирований в гибридном поиске.)
- **Фильтры**: доменные (SRD|Lore|Episode|Art) + по campaign_id для эпизодов.
- **k**: 8–12 (обычно 10) — баланс токенов/полезности.
- **LLM-rerank**: nano-модель на 12–20 кандидатов (дешево, но сильно чистит).

## 8.8 Процедуры обновления памяти

1.  **Post-turn-сводка**: сразу после применения эффектов/роллов/голосования движок пишет Episodic Summary и дельты отношений NPC.
2.  **Событийные сводки**: завершён квест, найден ключ, сменился флаг — пишем факт немедленно.
3.  **ArtCard**: если сцена получила арт — формируем 5–8 visual_tags из её текста (быстрый nano-вызов) и пишем карточку.

Зачем: семантическая память не расползается, а нарративная/визуальная консистентность повышается почти бесплатно.

## 8.9 Политики доступа, безопасности и приватности

- **Кто пишет**: движок/редактор; LLM — только читает через ретрив/инструменты.
- **PII**: минимизация; медиаметаданные без EXIF; TTL для аудио/ASR.
- **TTL**: сводки эпизодов — 90–180 дней; архив завершённых кампаний; ArtCards — по политике медиа.
- **Шифрование**: сторы/бэкапы — по настройкам окружения.
- **LangGraph Server**: чекпоинты тредов и долгие памяти — в локальный диск/БД; TTL/удаление через API; можно зашифровать.

## 8.10 Метрики качества и стоимость

### 8.10.1 Что меряем

- **Retrieval hit-rate** (сколько ретривов реально попало в ответ).
- **Rerank gain** (насколько rerank подвинул релевант).
- **Contradiction rate** (LLM говорит против лора/эпизодов).
- **Context tokens/use** и **cost/turn**.
- **Drift** (сколько фактов пришлось «исправлять» через lore_assert/HITL).

### 8.10.2 Стоимость (правило большого пальца)

- Текст + «Память37» (ретрив + сводки + эмбеддинги) — **сотые доли цента** за ход; дорогие части — **арт/TTS**.
- Сжатые размерности эмбеддингов (матрешка) заметно экономят RAM/стоимость без сильного падения качества.

## 8.11 Операции: версии, DR, перезалив индексов

- **Stage → Smoke retrieval → Swap alias (latest)** — атомарное включение новой версии лора.
- **Бэкапы**: снапшоты индексов + хранение сырья (JSON) → re-index скрипт.
- **Disaster recovery**: восстановление из снапшота индекса или re-index из сырья; эпизодические сводки и NPC-профили — из БД.

## 8.12 MCP/Tools (контракты инструментов для LLM)

- rules_lookup(term|rule_id) → URL/текст SRD-правила (read-only).
- lore_search(query, k, filters) → чанки/факты лора (read-only).
- session_fetch(party_id, k) → последние сводки/флаги.
- npc_profile(npc_id, party_id) → статик + динамика отношения.
- lore_assert(fact) → проверка факта на канон (true/false + подсказка источника).
- art_suggest(scene_id) → возврат ArtCard-тегов/стиля (для визуальной консистентности).

Зачем: все «чтения» из памяти — явные и трассируемые; запись — только детерминированно из движка.

## 8.13 Пресеты и конфиги (пример)

### 8.13.1 Индексы (YAML)

knowledge:

srd:

store: pgvector

embedding: text-embedding-3-large

dims: 1536

retrieval:

mode: hybrid # bm25 + vector

k_vector: 12

k_keyword: 50

fuse: rrf

lore:

store: pgvector

embedding: text-embedding-3-large

dims: 1024

retrieval:

mode: hybrid

k_vector: 10

k_keyword: 50

fuse: rrf

episode:

store: pgvector

embedding: text-embedding-3-large

dims: 768

retrieval:

mode: vector

k_vector: 8

filter: {party_id: "&lt;party&gt;"}

artcards:

store: pgvector

embedding: text-embedding-3-large

dims: 1024

retrieval:

mode: vector

k_vector: 8

### 8.13.2 Prompt-budget (рекомендация)

- System (тон/регламент): ≤ 300–500 ток.
- SRD/Lore чанки: 2–4 × 180–220 ток.
- Сводки эпизодов: 1–2 × 80–120 ток.
- NPC профиль: 1–2 × 60–100 ток.
- Art-контекст: 30–60 ток.
- Ввод пользователя: как есть.
- **Итог**: ~1.2–1.8k инпут токенов на сцену — комфортно для mini-модели.

## 8.14 FAQ/Шлюзы качества

- **Если ретрив пустой?** → деградируем: SRD/state, без лора; жёсткие факты из движка.
- **Если LLM «придумал» факт?** → lore_assert (false) → мягкая переформулировка, без нового факта; лог в аудит.
- **Если NPC «вдруг» поменял отношение?** → запрещено; только движок меняет disposition по правилам/флагам.
- **Если изображение «сломало канон» (цвет/символика)?** → ArtCard-теги обновляют запретные/обязательные маркеры для следующего арта сцены.

## 8.15 Артефакты главы (что должно появиться в репозитории)

- docs/memory/architecture.md — эта глава в кратком конспекте + диаграмма пайплайна.
- schemas/episodic_summary.schema.json, schemas/npc_profile.schema.json, schemas/artcard.schema.json.
- config/knowledge.yaml (как выше), config/prompt_budgets.yaml.
- mcp/tools/\*.yaml — контракты инструментов.
- ops/reindex.md, ops/alias_swap.md, ops/dr_knowledge.md.
- qa/memory_retrieval_golden/\*.json — golden-запросы для регресса ретрива.
- Тесты: unit (валидаторы схем), integration (retrieval + rerank), smoke (assembly).

## 8.16 DoR / DoD

**DoR (готово к работе):**

- Включены индексы SRD/Lore/Episode/ArtCards; гибрид-поиск с RRF настроен.
- Внедрены слой **threads/checkpoints/stores** для краткосрочной/долгой памяти (LangGraph).
- Выбраны эмбеддинги text-embedding-3-large с уменьшенной размерностью (Matryoshka).
- Описаны форматы **Episodic Summary**, **NPC Profile**, **ArtCard**; политики TTL/PII.
- Приняты MCP-инструменты чтения (assert/lookup/search/fetch).

**DoD (в репозитории):**

- Схемы JSON и валидаторы; конфиги индексов/параметров ретрива; prompt-budgets.
- Скрипты ingest/reindex + alias-swap; бэкапы и DR-план знаний.
- Метрики и дашборд для hit-rate/rerank-gain/cost-per-turn/contradiction-rate.
- Golden-queries и интеграционные тесты ретрива/assembly.

### Заключение (коротко)

«Память37» делает знание и память **управляемыми и дешёвыми**: гибридный ретрив (BM25+dense+RRF), многоуровневая память (threads/checkpoints + сводки/факты), сжатые эмбеддинги «матрёшка», строгая запись только движком, и **ArtCard** для визуальной консистентности. Выбрано то, что проще поддерживать и масштабировать, а ключевые решения опираются на актуальные практики (LangGraph persistence/memory, GraphRAG, hybrid-retrieval/RRF, Matryoshka embeddings).